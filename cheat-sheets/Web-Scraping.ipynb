{
 "metadata": {
  "name": "",
  "signature": "sha256:9cc6cc4a5a5e028a0f4910b750b7548db2e81fb355649ffd0ea174ece3f1c180"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes, we really need to use some data from a web page. Hopefully we can find the data in a useful format that we can work with, like CSV or even Excel files. But if it really only exists on a web page, we will have to use *web scraping* to get it. This is usually fiddly and frustrating, which is why it's a last resort.\n",
      "\n",
      "There are three steps to web scraping:\n",
      "\n",
      "1. **Fetch** the page\n",
      "2. **Parse** the HTML\n",
      "3. **Select** the data you want\n",
      "\n",
      "For this demo, we'll use [a list of country areas](https://www.cia.gov/library/publications/the-world-factbook/rankorder/2147rank.html) from the CIA World Factbook. This is available in better formats, but it's a good illustration."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "import lxml.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fetch the data\n",
      "response = requests.get('https://www.cia.gov/library/publications/the-world-factbook/rankorder/2147rank.html')\n",
      "response.text[:200]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "u'<!doctype html>\\n<!--[if lt IE 7]> <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\" lang=\"en\"> <![endif]-->\\n<!--[if IE 7]>    <html class=\"no-js lt-ie9 lt-ie8\" lang=\"en\"> <![endif]-->\\n<!--[if IE 8]>    <html c'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At the moment, this is just one long string. We need to *parse* it so the computer knows about the structure."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Parse the HTML\n",
      "html = lxml.html.fromstring(response.text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To work out how to get the bit of data we want, go to the page in your browser, right click on one of the things we want, and click 'Inspect element' to examine the HTML structure of the page.\n",
      "\n",
      "We get the data we want using XPath, a special mini-language for selecting elements in HTML and XML documents. Here, `//td[@class=\"region\"]` matches all `<td>` (table data) tags anywhere in the page with the attribute `class=\"region\"`. More information about XPath is available [here](http://www.w3schools.com/xpath/)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "countries = []\n",
      "for td in html.xpath(\"\"\"//td[@class=\"region\"]\"\"\"):\n",
      "    countries.append(td.text_content())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(countries)\n",
      "countries[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "253\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[u'Country Comparison\\xa0::\\xa0Area',\n",
        " 'Russia',\n",
        " 'Canada',\n",
        " 'United States',\n",
        " 'China',\n",
        " 'Brazil',\n",
        " 'Australia',\n",
        " 'India',\n",
        " 'Argentina',\n",
        " 'Kazakhstan']"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "areas = []\n",
      "for td in html.xpath(\"\"\"//td[@class=\"category_data\"]\"\"\"):\n",
      "    areas.append(td.text_content())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(areas)\n",
      "areas[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "252\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['       17,098,242',\n",
        " '        9,984,670',\n",
        " '        9,826,675',\n",
        " '        9,596,960',\n",
        " '        8,514,877',\n",
        " '        7,741,220',\n",
        " '        3,287,263',\n",
        " '        2,780,400',\n",
        " '        2,724,900',\n",
        " '        2,381,741']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "areas_num = []\n",
      "for a in areas:\n",
      "    areas_num.append(int(a.strip().replace(',', '')))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll match them back up using Python's `zip()` function to join two lists together. Remember that the first name in the countries list is spurious, so we need to throw it away."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip(countries[1:], areas_num)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[('Russia', 17098242),\n",
        " ('Canada', 9984670),\n",
        " ('United States', 9826675),\n",
        " ('China', 9596960),\n",
        " ('Brazil', 8514877),\n",
        " ('Australia', 7741220),\n",
        " ('India', 3287263),\n",
        " ('Argentina', 2780400),\n",
        " ('Kazakhstan', 2724900),\n",
        " ('Algeria', 2381741)]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Exercise"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pick another page from the CIA world factbook, or if you're feeling adventurous, another page with data from elsewhere on the internet. Scrape data from it using these tools."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}