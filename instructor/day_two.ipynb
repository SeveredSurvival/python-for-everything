{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Web scraping vs APIs  - what's the difference?\n",
    "When you access data on the web, you typically download a resource. This can occur on a browser, or in your Python console. Because our interaction is primarily visual, information returned is in HTML, a markup language, that delivers both content and rules about how the content is to be presented (fonts, text size, bold, arrangement). By contrast, APIs typically are built to only return data. For this reason, the data is typically returned in XML or JSON formats. The following are examples of each: [examples here] \n",
    "\n",
    "Similarly, saving a web page or going to Source in Developer Tools allows you to view the html code associated with each. \n",
    "\n",
    "\n",
    "### Note on Robots:\n",
    "We also hear a lot about robots. A robot is ... to accomplish any kind of automated task. However, if you... Bots can be built to extract data from APIs or web scraping. Note that accessing APIs through the console does not necessarily mean it is a bot. If you manually send requests on the console to download specific resources, that is not a bot. Requires that it be automated. In the next section, we will discuss a text file called \"robots.txt\" that is typically contained in the root folder, that contains instructions to bots \n",
    "\n",
    "For instance, a bot can click through every post on a forum, downloading files for each looking for a specific word or text. In our example, we show how to do this for Wikipedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Menagerie of tools: crawlers, spiders, scrapers - what's the difference? \n",
    "Web crawlers or spiders comes from. An image of long, spindly legs, traversing from hyperlink to hyperlink. It is these automated crawlers that continually traverse the web and index new or changed content, that search engines used to update and present the most relevant results to your search requests. \n",
    "\n",
    "Web scraping is a little different. While many of the tools used may be identical or similar, web scraping \"focuses more on the transformation of unstructured data on the web, typically in HTML format, into structured data that can be stored and analyzed in a central local database or spreadsheet.\" (https://en.wikipedia.org/wiki/Web_scraping) \n",
    "\n",
    "In many cases, to the server, these processes look somewhat identical. Resources are sent in response to requests. Rather, it is what is done to those resources after they are sent, and the overall goal, that differentiates web crawling and scraping. Most websites want crawlers to find them so their pages appear on popular search engines, but see no clear-cut benefit when their content is parsed and converted into usable data. Beyond research, many companies also use web scraping (in a legal grey area or illegally) to repurpose content, etc, a real estate website scraping data from Craigslist to re-post as listings on their website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Considerate robots and legality \n",
    "The use of robots.txt file is a convention. \n",
    "\n",
    "identifies the links, and highlights specific crawlers. Let's take a look at reddit's [insert reddit's privacy policy]\n",
    "\n",
    "Twitter's privacy policy. [insert Twitter privacy policy]  \n",
    "\n",
    "Blogs, for instance, or many forum sites do not have APIs available. \n",
    "\n",
    "Most frequent is getting your IP blocked temporarily or permanently. In addition, if you plan to publish your results for research, contacting the agency is probably a good idea. \n",
    "\n",
    "In summary:   \n",
    "1) Find the websites' robots.txt and do not access those pages through your bot  \n",
    "2) Make sure your bot does not make too many requests in a specific period (etc. by using Python's sleep.wait function)   \n",
    "3) Look up the website's term of use or terms of service.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Examining the webpage structure\n",
    "\n",
    "The first step is to examine the webpage in your browser, using developer tools (Firefox/Chrome). First, identify the element that you want to pull data from. In this case, a series of links. Forum traversal. \n",
    "\n",
    "For this case, we concentrate on the box that appears at the side of each of the company's pages. \n",
    "\n",
    "While we've identified visually where we want to pull the element from, this may or may not translate into code. In our case, thankfully, the pages have similar enough structure. HTML has an optional category called \"class\", which, among other uses, allows the website to specifiy how the formatting of an element should look (using what is called css). For our purposes, we can use the \"infobox vcard\" class to tell the program which box we want to pull out and use.\n",
    "\n",
    "[click inspect element] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Interacting with the webpage through the console \n",
    "\n",
    "After examining the webpage structure through your browser, now it's time to interact with the underlying html code (what you see in the inspect element page) directly in your console. Both processes are useful to coming up with a strategy of how (and whether) data from the website can be scraped. \n",
    "\n",
    "First, import urllib2 and BeautifulSoup. Downloading a html copy of the site is as simple as: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The W's: **W**hat, **w**hy, and probably even ho**w**.\n",
    "\n",
    "### What is a bot?\n",
    "\n",
    "A bot is a program that runs user defined tasks in an automated way.\n",
    "\n",
    "### Why would you want a bot?\n",
    "\n",
    "For fun! For laughs. For productivity.\n",
    "\n",
    "### What can you do with a bot?\n",
    "\n",
    "You can test code. You can use it to collect data. On Twitter, you can use a bot to post automated status updates. You can even use a bot can alert you when certain events happen (inside or outside of Twitter).\n",
    "\n",
    "At the D-Lab, we pull training/workshop information from our calendar, generate a tweet, and post it to the @DLabAtBerkeley account. We're trying to add more functionality, such as including instructor usernames in the tweets or processing the descriptions and titles to come up with a short, descriptive summary.\n",
    "\n",
    "A team of researchers led by Jacob Eisenstein used a bot to collect 107 million tweets, which were then used ot track the diffusion of linguistic variants across the United States.\n",
    "\n",
    "![Figure1](https://d262ilb51hltx0.cloudfront.net/max/800/1*mlnsT2x2SL-e7JMo3HpWFg.png)\n",
    "\n",
    "There are lots of people doing interesting things with bots on Twitter. For inspiration, see: http://qz.com/279139/the-17-best-bots-on-twitter/.\n",
    "\n",
    "Both of the world's most famous vocab-limited characters have Twitter accounts that reply with their catchphrases to anyone who mentions their name.\n",
    "\n",
    "[Hodor](https://twitter.com/hodorhodorhodor)\n",
    "\n",
    "[Groot](https://twitter.com/GrootBot)\n",
    "\n",
    "### How can you do it?\n",
    "Read on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API** is shorthand for **A**pplication **P**rogramming **I**nterface, which is in turn computer-ese for a middleman.\n",
    "\n",
    "Think about it this way. You have a bunch of things on your computer that you want other people to be able to look at. Some of them are static documents, some of them call programs in real time, and some of them are programs themselves.\n",
    "\n",
    "### Solution 1\n",
    "\n",
    "You publish login credentials on the internet, and let anyone log into your computer\n",
    "\n",
    "Problems:\n",
    "\n",
    "1. People will need to know how each document and program works to be able to access their data\n",
    "\n",
    "2. You don't want the world looking at your browser history\n",
    "\n",
    "### Solution 2\n",
    "\n",
    "You paste everything into HTML and publish it on the internet\n",
    "\n",
    "Problems:\n",
    "\n",
    "1. This can be information overload\n",
    "\n",
    "2. Making things dynamic can be tricky\n",
    "\n",
    "### Solution 3\n",
    "\n",
    "You create a set of methods to act as an intermediary between the people you want to help and the things you want them to have access to.\n",
    "\n",
    "Why this is the best solution:\n",
    "\n",
    "1. People only access what you want them to have, in the way that you want them to have it\n",
    "\n",
    "2. People use one language to get the things they want\n",
    "\n",
    "Why this is still not Panglossian:\n",
    "\n",
    "1. You will have to explain to people how to use your middleman\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Twitter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter is visible \n",
    "\n",
    "1. Currently 8th ranked website worldwide, 7th in the US\n",
    "\n",
    "2. 288 million users per month\n",
    "\n",
    "3. 500 million tweets per day\n",
    "\n",
    "### Twitter is democratic\n",
    "\n",
    "1. 80% of users are on mobile devices\n",
    "\n",
    "2. Support for 33 languages\n",
    "\n",
    "3. American Twitter users are disproprtionately from underrepresented communities\n",
    "\n",
    "4. Fun Fact: the third most-searched for term leading to Twitter, after 'Twitter' and 'CNN' is the name of a porn actress\n",
    "\n",
    "### Twitter is information\n",
    "\n",
    "1. User histories\n",
    "\n",
    "2. User (and tweet) location\n",
    "\n",
    "3. User language\n",
    "\n",
    "4. Tweet popularity\n",
    "\n",
    "5. Tweet spread\n",
    "\n",
    "6. Conversation chains\n",
    "\n",
    "### Twitter is antidemocratic\n",
    "\n",
    "1. Mexico's government has been accused of using Twitter for false flag operations\n",
    "\n",
    "2. GCHQ has a software library purportedly designed to modulate public opinion\n",
    "\n",
    "3. Someone here used a Twitter bot to occupy all of State Bird Provision's table reservations\n",
    "\n",
    "### Twitter is opaque\n",
    "\n",
    "1. Twitter's API does not return all tweets that match your search criteria\n",
    "\n",
    "2. The sampling method is not published, and can change without notice\n",
    "\n",
    "3. Location information is not necessarily provided by GPS\n",
    "\n",
    "### Twitter is spam\n",
    "\n",
    "1. Two years ago, approximately 20 million Twitter accounts were advertising bots\n",
    "\n",
    "2. Appoximately 1/3 of any accounts followers are not humans\n",
    "\n",
    "3. Of the top ten accounts (by followers), eight are celebrities (the other two are YouTube and the current President)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple, right? 140 characters. Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/first_tweet.json','r') as f:\n",
    "    a_tweet = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print a_tweet['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(a_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have access to more than just the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> JSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a lightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of JavaScript)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure. Think of it like Python's `dict` type. Keys and values, collectively referred to as items, are separated by a colon. Multiple items are separated by commas. Keys must be immutable and unique to a particular `dict`. Values can be of any type, including `list` or even another `dict`. Dictionaries are always surrounded by braces, `{}`. \n",
    "\n",
    "In JSON, it's common practice to have nested or hierarchical dictionaries. For example, some Reddit endpoints return JSON objects that are six dictionaries deep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how can you access data within a Python `dict`? You first need the keys. To get the keys, you must look at the data or use the `.keys()` method, which returns a list of the key names in an arbitrary order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_tweet.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the values? Use the dictionary name along with the key in square brackets. We used this above to access the tweet's text. If you're interested in knowing when the tweet was created, use the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_tweet['user'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_tweet['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is given in UTC. The offset is shown by the `+0000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing about JSON data or Python dictionaries is that they can have a nested structure. What if we want access to the values associated with the `entities` key?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_tweet['entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a dictionary. To access any of _those_ values, use the appropriate key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_tweet['entities']['hashtags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there are no hashtags associated with this tweet, so it's just an empty `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(a_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you proceed, you'll need four pieces of information.\n",
    "\n",
    "* consumer_key\n",
    "* consumer_secret\n",
    "* access_token_key\n",
    "* access_token_secret\n",
    "\n",
    "While signed in to your Twitter account, go to: https://apps.twitter.com/. Follow the prompts to generate your keys and access tokens. You'll need to have a phone number associated with your account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how do we actually access the Twitter API? Well, there are several ways. To search for something, you can use the search URL, which looks like: https://api.twitter.com/1.1/search/tweets.json?q=%40twitterapi. The `q` is the query parameter. You can replace it with anything you want. However, if you follow this link, you'll get an error because your request was not authenticated.\n",
    "\n",
    "For more information on the REST APIs, end points, and terms, check out: https://dev.twitter.com/rest/public. For the Streaming APIs: https://dev.twitter.com/streaming/overview."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we'll use Jonas Geduldig's `TwitterAPI` module: https://github.com/geduldig/TwitterAPI. The nice thing about modules such as this one--yes, there are others--is that it handles the OAuth. `TwitterAPI` supports both the REST and Streaming APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwitterAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To authenticate, run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "consumer_key = '9cQ7SNtWsmTTfta8Gv5y8svWD'\n",
    "consumer_secret = 'kjJllUPEJefFQ4Dfr6dBXDETiQaVWFXTt0zLSNMy8tY8F8IpqK'\n",
    "access_token_key = '3129088320-dIfoDZOt5cIKVCFnJpS0krt3oCYPB13rk5ITavI'\n",
    "access_token_secret = 'H41REM344zgKCvJenCGGsF1JbFSK8I1r1WvFrc8Fs74jg'\n",
    "\n",
    "api = TwitterAPI(consumer_key, consumer_secret, access_token_key, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a Twitter account for this talk. Feel free to use the following keys and access tokens to familiarize yourself with the API. But, be aware that Twitter imposes rate limits, and that these rate limits are different for different kinds of API interactions.\n",
    "\n",
    "> Search will be rate limited at 180 queries per 15 minute window for the time being, but we may adjust that over time.\n",
    "\n",
    "> \\- Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the end point is the same as in the URL example, `search/tweets`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = api.request('search/tweets', {'q':'technology'})\n",
    "for item in r:\n",
    "    print item "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API supports what it calls query operators, which modify the search behavior. For example, if you want to search for tweets where a particular user is mentioned, include the at-sign, `@`, followed by the username. To search for tweets sent to a particular user, use `to:username`. For tweets from a particular user, `from:username`. For hashtags, use `#hashtag`.\n",
    "\n",
    "For a complete set of options: https://dev.twitter.com/rest/public/search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things clearer, let's use variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_point = 'search/tweets'\n",
    "parameters = {\n",
    "    'q':'from:Engadget', \n",
    "    'count':1\n",
    "}\n",
    "\n",
    "r = api.request(end_point, parameters)\n",
    "for item in r:\n",
    "    print item['text'] + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search user timelines. Notice the change in the end point and parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_point = 'statuses/user_timeline'\n",
    "parameters = {\n",
    "    'screen_name':'UCBerkeley', \n",
    "    'count':5\n",
    "}\n",
    "\n",
    "r = api.request(end_point, parameters)\n",
    "for item in r:\n",
    "    print item['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_point = 'search/tweets'\n",
    "parameters = {\n",
    "    'q':'technology',\n",
    "    'geocode':'37.871667,-122.272778,5km', # UC Berkeley\n",
    "    'count':1\n",
    "}\n",
    "\n",
    "r = api.request(end_point, parameters)\n",
    "for item in r:\n",
    "        print item['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_point = 'search/tweets'\n",
    "parameters = {\n",
    "    'q':'*',\n",
    "    'lang':'fr',\n",
    "    'count':1\n",
    "}\n",
    "\n",
    "r = api.request(end_point, parameters)\n",
    "for item in r:\n",
    "    print item['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_point = 'statuses/filter'\n",
    "parameters = {\n",
    "    'q':'coding',\n",
    "    'locations': '-180,-90,180,90'\n",
    "}\n",
    "\n",
    "r = api.request(end_point, parameters)\n",
    "tweets = r.get_iterator()\n",
    "for i in range(15):\n",
    "    t = tweets.next()\n",
    "    print t['place']['full_name'] + ', ' + t['place']['country'] + ': ' + t['text'], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other half of the game is posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_point = 'statuses/update'\n",
    "parameters = {\n",
    "    'status':'.IPA rettiwT eht tuoba nraeL'\n",
    "}\n",
    "\n",
    "r = api.request(end_point, parameters)\n",
    "print r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you know how to search for tweets, how about we save them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in r:\n",
    "    filename = item['id_str'] + '.json'\n",
    "    with open(filename,'w') as f:\n",
    "        json.dump(item,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you are doing a lot of these, it will be faster and easier to use a non-relational database like MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real beauty of bots is that they are designed to work without interaction or oversight. Imagine a situation where you want to write a Twitter bot that replies 'HOORAY!' every time someone posts on Twitter that they were accepted to Cal. One option is to write a python script like this and call it by hand every minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "r = api.request('search/tweets', {'q':'accepted berkeley'})\n",
    "for item in r:\n",
    "    username = item['user']['screen_name']\n",
    "    parameters = {'status':'HOORAY! @' + username}\n",
    "    r = api.request('statuses/update', parameters)\n",
    "    time.sleep(5)\n",
    "    print r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you are a human that needs to eat, sleep, and be social with other humans. Luckily, most `UNIX` based systems have a time-based daemon called `cron` that will run scripts like this *for you*. The way that `cron` works is it reads in files where each line has a time followed by a job (these are called cronjobs). They looks like this:\n",
    "\n",
    "```\n",
    "0 * * * * python twitter_bot.py\n",
    "```\n",
    "\n",
    "This is telling `cron` to execute `python twitter_bot.py` at `0` seconds, every minute, every hour, every day, every year, until the end of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# That thing after crontab is a lowercase L even though it looks like a 1\n",
    "# This will execute directly through your shell, so use at your own risk\n",
    "# Make sure you replace the <> with the file path\n",
    "!crontab -l | { cat; echo \"0 * * * * python <absolute path to>twitter_bot.py\"; } | crontab -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using a mac (especially Mavericks or newer), Apple prefers that you use their init library, called `launchd`. `launchd` is a bit more complicated, and requires that you create an xml document that will be read by Apple's init service:\n",
    "\n",
    "```\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<!DOCTYPE plist PUBLIC \"-//Apple//DTD PLIST 1.0//EN\" \"http://www.apple.com/DTDs/PropertyList-1.0.dtd\">\n",
    "<plist version=\"1.0\">\n",
    "<dict>\n",
    "    <key>Label</key>\n",
    "    <string>twitter.bot</string>\n",
    "    <key>ProgramArguments</key>\n",
    "    <array>\n",
    "        <string>python</string>\n",
    "        <string>twitter_bot.py</string>\n",
    "    </array>\n",
    "    <key>StartCalendarInterval</key>\n",
    "    <dict>\n",
    "        <key>Minute</key>\n",
    "        <integer>00</integer>\n",
    "    </dict>\n",
    "</dict>\n",
    "</plist>\n",
    "```\n",
    "\n",
    "We won't be messing with `launchd` for this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Now it is time for you to make your own twitter bot!\n",
    "\n",
    "To get you started, here is a template in python. You should modify the search parameters and post parameters to get the bot to act the way you want. \n",
    "\n",
    "You might find it easier to copy this out of the notebook into a python script and run it from your terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "import time\n",
    "\n",
    "consumer_key = '9cQ7SNtWsmTTfta8Gv5y8svWD'\n",
    "consumer_secret = 'kjJllUPEJefFQ4Dfr6dBXDETiQaVWFXTt0zLSNMy8tY8F8IpqK'\n",
    "access_token_key = '3129088320-dIfoDZOt5cIKVCFnJpS0krt3oCYPB13rk5ITavI'\n",
    "access_token_secret = 'H41REM344zgKCvJenCGGsF1JbFSK8I1r1WvFrc8Fs74jg'\n",
    "\n",
    "api = TwitterAPI(consumer_key, consumer_secret, access_token_key, access_token_secret)\n",
    "\n",
    "request_parameters = {} #Enter your search parameters here\n",
    "\n",
    "def main():\n",
    "    while True: #You may want to set a condition here\n",
    "        r = api.request('search/tweets', request_parameters)\n",
    "        if r.status_code == 200:\n",
    "            for item in r:\n",
    "                if True: #You may want to set a condition here\n",
    "                    post_parameters = {} #Enter your post parameters here\n",
    "                    p = api.request('statuses/update', post_parameters)\n",
    "                    print p.status\n",
    "                    time.sleep(15)\n",
    "        if r.status_code == 420: #If Twitter is throttling you\n",
    "            break\n",
    "        if r.status_code == 429: #If you are exceeding the rate limit\n",
    "            time.sleep(60)\n",
    "        \n",
    "if __name__ == 'main':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can see an example of how to set conditions and search parameters [in the code](https://github.com/deniederhut/city_mood/blob/master/city_mood.py) that powers the [berkeleymood Twitter bot](https://twitter.com/BerkeleyMood)\n",
    "\n",
    "If you have tried to run this, or some of the earlier code in this notebook, you have probably encountered some of Twitter's error codes. Here are the most common, and why you are triggering them.\n",
    "\n",
    "1. `400 = bad request` - This means the API (middleman) doesn't like how you formatted your request. Check the API documentation to make sure you are doing things correctly.\n",
    "\n",
    "2. `401 = unauthorized` - This either means you entered your auth codes incorrectly, or those auth codes don't have permission to do what you're trying to do. It takes Twitter a while to assign posting rights to your auth tokens after you've given them your phone number. If you have just done this, wait five minutes, then try again.\n",
    "\n",
    "3. `403 = forbidden` - Twitter won't let you post what you are trying to post, most likely because you are trying to post the same tweet twice in a row within a few minutes of each other. Try changing your status update. If that doesn't fix it, then you are either:\n",
    "\n",
    "    A. Hitting Twitter's daily posting limit. They don't say what this is.\n",
    "        \n",
    "    B. Trying to follow too many people, rapidly following and unfollowing the same person, or are otherwise making Twitter think you are a spambot\n",
    "\n",
    "4. `420 = enhance your calm` - Simultaneously a joke about [San Rafael High students](http://www.huffingtonpost.com/2010/04/20/420-meaning-the-true-stor_n_543854.html) and [Sylverster Stallone's prescient film about the future](https://youtu.be/YnSIOlF132w), it has been deprecated in favor of:\n",
    "\n",
    "5. `429 = too many requests` - This means that you have exceeded Twitter's rate limit for whatever it is you are trying to do. Increase your  `time.sleep()`  value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
